{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03_-_Markov_Decision_Process.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNwvhCg8a89iMwwgNv/zPYD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aplneto/IF998/blob/main/03_-_Markov_Decision_Process.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Processos finitos de decisão de Markov\n",
        "\n",
        "_[Capítulo 3](https://web.stanford.edu/class/psych209/Readings/SuttonBartoIPRLBook2ndEd.pdf)_\n",
        "\n",
        "![image.png]\n",
        "\n",
        "* No tempo $t \\in \\mathcal{N}$\n",
        "  * O estado $S_t \\in \\mathcal{S}$: resepresentação do ambiente\n",
        "  * Ação $\\mathcal{A}(S_t)$: ação escolhida\n",
        "  * Recompensa $R_{t+1}\\in \\mathcal{R}$: recompensa instantânea\n",
        "  * Novo estado $S_{t+1}$\n",
        "\n",
        "\n",
        "[image.png]: data:image/png;base64,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"
      ],
      "metadata": {
        "id": "mVLN9_9lnUyT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MDP Finito:\n",
        "\n",
        "![mdp.png](https://upload.wikimedia.org/wikipedia/commons/thumb/a/ad/Markov_Decision_Process.svg/400px-Markov_Decision_Process.svg.png)\n",
        "\n",
        "* $\\mathcal{S}$, $\\mathcal{A}$ e $\\mathcal{R}$ são conjuntos finitos.\n",
        "* Dada uma trajetória: $S_0, A_0, R_1, A_1, R_2, A_2, R_3,...$\n",
        "* A dinâmica da MDP é dada pela distribuição:\n",
        "\n",
        "\\begin{equation}\n",
        "p(s\\prime,r|s,a)\\doteq Pr\\{S_t=s\\prime,R_t=r|S_{t-1}=s,A_{t-1}=a\\}\n",
        "\\end{equation}"
      ],
      "metadata": {
        "id": "w4R6-H6Ktq4u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "\n",
        "# Probabilidades de triplas (Estado, Ação, Novo Estado)\n",
        "estado_acao = numpy.zeros((3, 2, 3))\n",
        "\n",
        "# Probabilidade de, no estado 0, ao escolher a ação 0, permanecer no estado 0\n",
        "estado_acao[0][0][0] = 0.5\n",
        "\n",
        "# Probabilidade de, no estado zero, ao escolher a ação 0, ir para o estado 1\n",
        "estado_acao[0][0][1] = 0\n",
        "\n",
        "# Probabilidade de, no estado zero, ao escolher a ação 0, ir para o estado 2\n",
        "estado_acao[0][0][2] = 0.5\n",
        "\n",
        "estado_acao[0][1] = [0, 0, 1]\n",
        "estado_acao[1][0] = [0.7, 0.1, 0.2]\n",
        "estado_acao[1][1] = [0, 0.95, 0.05]\n",
        "estado_acao[2][0] = [0.4, 0, 0.6]\n",
        "estado_acao[2][1] = [0.3, 0.3, 0.4]\n",
        "\n",
        "# Recompensas das ações transições\n",
        "recompensas = numpy.zeros((3, 2, 3))\n",
        "\n",
        "# recompensas possíveis ao escolher a ação 0 no estado 1\n",
        "recompensas[1][0] = [5, 0, 0]\n",
        "# recompensas possíveis ao escolher a ação 1 no estado 2\n",
        "recompensas[2][1] = [-1, 0, 0]"
      ],
      "metadata": {
        "id": "3OxHbw0Tz3Ea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Interface Agente-Ambiente\n",
        "\n",
        "* Probabilidade de transição de estados:\n",
        "\n",
        "  $\n",
        "  p(s\\prime|s,a)\\doteq Pr\\{S_t=s\\prime|S_{t-1}=s,A_{t-1}=a\\}=\\sum_{r\\in R}p(s\\prime,r|s,a)\n",
        "  $\n",
        "\n",
        "* Recompensa esperada para um par estado-ação:\n",
        "\n",
        "  $\n",
        "  r(s,a)\\doteq\\mathbb{E}[R_t|S_{t-1}=s,A_{t-1}=a]=\\sum_{r\\in \\mathcal{R}}r\\sum_{s\\prime\\in\\mathcal{S}}p(s\\prime,r|s,a)\n",
        "  $\n",
        "\n",
        "* Recompensa esperada para uma tripla estado-ação-estado\n",
        "\n",
        "  $\n",
        "  r(s,a,s\\prime)\\doteq\\mathbb{E}[R_tZS_{t-1}=s,A_{t-1}=a,S_t=s\\prime]=\\sum_{r\\in\\mathcal{R}}r\\frac{p(s\\prime,r|s,a)}{p(s\\prime|s,a)}\n",
        "  $"
      ],
      "metadata": {
        "id": "eH1-h5mbtt1O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_Q9l0zSaOQqV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Objetivos e Recompensa\n",
        "\n",
        "* Recompensa:\n",
        "  * Forma de comunicação com o agente\n",
        "  * Indica se ele está indo pelo caminho certo ou errado\n",
        "* Objetivo:\n",
        "  * Maior expectativa de valor acumulado do sinal de recompensa"
      ],
      "metadata": {
        "id": "pDdjSlKb4VAH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Retornos e Episódios\n",
        "\n",
        "* Retorno acumulado para tarefas episódicas:\n",
        "  * com time step final T: $G_t\\doteq R_{t+1}+R_{t+2}+R_{t+3}+...+R_T$\n",
        "  \\begin{equation}\n",
        "  G_t=\\sum_{t\\prime=t+1}^T R_{t\\prime}\n",
        "  \\end{equation}\n",
        "* Retorno para tarefas contínuas:\n",
        "  * Recompenas sem descontos\n",
        "  \\begin{equation}\n",
        "  G_t=\\sum^{+\\infty}_{t\\prime=t+1}R_{t\\prime}\\text{ (chamado de \"retorno em t\")}\n",
        "  \\end{equation}\n",
        "\n",
        "* Para tarefas contínuas:\n",
        "  * Recompensas com descontos com<br>\n",
        "  $\n",
        "  G_t\\doteq R_{t=1}+\\gamma R_{t+2}+\\gamma^2R_{t+3}+\\gamma^3R_{t+4}+...\n",
        "  $<br>\n",
        "  $\n",
        "  G_t=\\sum^{+\\infty}_{k=0}\\gamma^kR_{t+1+k}\n",
        "  $<br>\n",
        "  e $0 \\le\\gamma\\le 1$. Tipicamente [0.9, 0.99]\n",
        "* $\\gamma$ é chamado de _discount factor_ e valores maiores dão mais valor a recompensas em futuro próximo em determinto da recompensa total acumulada. Compensa a incerteza sobre os estados futuros.\n",
        "\n",
        "* Propriedade recursiva\n",
        "\n",
        "\\begin{aligned}\n",
        "G_t\\doteq R_{t=1}+\\gamma R_{t+2}+\\gamma^2R_{t+3}+\\gamma^3R_{t+4}+...\\\\\n",
        "= R_{t+1} + \\gamma(R_{t+2}+\\gamma R_{t+3} + \\gamma^2R_{t+4} + ...\\\\\n",
        "= R_{t+1}+\\gamma G_{t+1}\\\\\n",
        "\\end{aligned}\n",
        "\n",
        "* Finitude se |R| ≤ M\n",
        "\\begin{equation}\n",
        "|G_t| \\le\n",
        "\\begin{cases}\n",
        "(T - t -1)M\\text{ if }T<\\infty\n",
        "\\\\\\\\\n",
        "M\\frac{1}{1-\\gamma}\\text{ otherwise}\n",
        "\\end{cases}\n",
        "\\sum_{k=0}^{\\infty}\\gamma^k=\\frac{1}{1-\\gamma}\n",
        "\\end{equation}\n",
        "\n",
        "* Notação unificada para tarefas episódicas e contínuas:\n",
        "\n",
        "![unified-notation.png]\n",
        "\n",
        "* Formas:\n",
        "  * Episódica: $G_t=\\sum^{T}_{t\\prime=t+1}R_{t\\prime}$\n",
        "  * Contínua: $G_t = \\sum_0^{+\\infty}\\gamma^kR_{t+1+k}$\n",
        "  * Unificada: $G_t=\\sum^T_{k=t+1}\\gamma^{k-t-1}R_k$\n",
        "\n",
        "* Com $T=\\infty$ ou $\\gamma<1$, mas não ambos.\n",
        "[unified-notation.png]: data:image/png;base64,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"
      ],
      "metadata": {
        "id": "xDTSwyMV5UH2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H5QzL_aYm6cO"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Políticas e Valores\n",
        "\n",
        "* Assumindo um agente seguindo uma política $\\pi(a|s)$\n",
        "* Função Valor de estado:\n",
        "\\begin{equation}\n",
        "v_\\pi(s)=\\mathbb{E}_\\pi[G_t|S_t=s]=\\mathbb{E}_\\pi\\left[\\sum^\\infty_{k=0}\\gamma^kR_{t+k+1}\\middle|S_t=s\\right]\n",
        "\\end{equation}\n",
        "* Função Valor da Ação (qualidade da ação):\n",
        "\\begin{equation}\n",
        "q_\\pi(s,a)=\\mathbb{E}_\\pi[G_t|S_t=s, A_t=a]=\\mathbb{E}_\\pi\\left[\\sum^\\infty_{k=0}\\gamma^kR_{t+k+1}\\middle|S_t=s, A_t=a\\right]\n",
        "\\end{equation}\n",
        "* Assumindo que $\\pi(a|s)$ seja estacionária"
      ],
      "metadata": {
        "id": "7PISEa0tDKg9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [Gridworld][fonte]\n",
        "\n",
        "![gridworld.png](https://miro.medium.com/max/507/1*iX-Fu5YzUZ8CNEZ86BvfKA.png)\n",
        "\n",
        "**Exemplo 3.5: Gridworld** A figura 3.2 (acima) mostra um ambiente gridworld retangular de uma MDP finita simples. As células do grid representam os possíveis estados do ambiente. Em cada célula, quatro ações são possíveis: *norte*, *sul*, *leste* e *oeste*, que fazem o agente se mover na direção respectiva no grid. Ações que fariam o agente sair do grid não mudam a sua posição e resultam numa recompensa de $-1$. Outras ações resultam numa recompensa de $0$, exceto ações tomadas a partir dos estados especiais $A$ e $B$. Ações tomadas a partir do estado $A$ resultam numa recompensa de $+10$ e levam o agente para a posição $A^\\prime$. Ações tomadas do estado $B$ resultam numa recompensa de +5 e levam o agentepara o estado $B^\\prime$.\n",
        "\n",
        "[fonte]: https://realdiganta.medium.com/coding-the-gridworld-example-from-deepminds-reinforcement-learning-course-in-python-17d74335fcbc"
      ],
      "metadata": {
        "id": "TpeQLRo8O_hG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5 x 5 possíveis estados, 4 ações possíveis [N, S, L, O]\n",
        "rewards = numpy.zeros((5, 5, 4))\n",
        "\n",
        "for n in range(0, 5):\n",
        "  rewards[0][n] = [-1, 0, 0, 0] # Linha superior\n",
        "  rewards[n][0] = [0, 0, 0, -1] # Coluna esquerda\n",
        "  rewards[4][n] = [0, -1, 0, 0] # Linha inferior\n",
        "  rewards[n][4] = [0, 0, -1, 0] # Coluna direita\n",
        "\n",
        "rewards[0][0] = [-1, 0, 0, -1] # Canto superior esquerdo\n",
        "rewards[4][0] = [0, -1, 0, -1] # Canto inferior esquerdo\n",
        "rewards[4][4] = [0, -1, -1, 0] # Canto inferior direito\n",
        "rewards[0][4] = [-1, 0, -1, 0] # Canto superior direito\n",
        "\n",
        "rewards[0][1] = [10] * 4 # Estado A\n",
        "rewards[0][3] = [5] * 4 # Estado B\n",
        "\n",
        "print(rewards)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "267jV-ULHJGh",
        "outputId": "d3a0e059-1b02-4eca-a67e-8e8d54de6f44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[-1.  0.  0. -1.]\n",
            "  [10. 10. 10. 10.]\n",
            "  [-1.  0.  0.  0.]\n",
            "  [ 5.  5.  5.  5.]\n",
            "  [-1.  0. -1.  0.]]\n",
            "\n",
            " [[ 0.  0.  0. -1.]\n",
            "  [ 0.  0.  0.  0.]\n",
            "  [ 0.  0.  0.  0.]\n",
            "  [ 0.  0.  0.  0.]\n",
            "  [ 0.  0. -1.  0.]]\n",
            "\n",
            " [[ 0.  0.  0. -1.]\n",
            "  [ 0.  0.  0.  0.]\n",
            "  [ 0.  0.  0.  0.]\n",
            "  [ 0.  0.  0.  0.]\n",
            "  [ 0.  0. -1.  0.]]\n",
            "\n",
            " [[ 0.  0.  0. -1.]\n",
            "  [ 0.  0.  0.  0.]\n",
            "  [ 0.  0.  0.  0.]\n",
            "  [ 0.  0.  0.  0.]\n",
            "  [ 0.  0. -1.  0.]]\n",
            "\n",
            " [[ 0. -1.  0. -1.]\n",
            "  [ 0. -1.  0.  0.]\n",
            "  [ 0. -1.  0.  0.]\n",
            "  [ 0. -1.  0.  0.]\n",
            "  [ 0. -1. -1.  0.]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def mover(dir, pos):\n",
        "  '''\n",
        "  Retorna a recompensa recebida e a nova posição do agente no grid\n",
        "\n",
        "    Parâmetros:\n",
        "        dir (str): Caractere ou numero inteiro que indica a direção\n",
        "          * 0 ou N -> Norte\n",
        "          * 1 ou S -> Sul\n",
        "          * 2 ou L -> Leste\n",
        "          * 3 ou O -> Oeste\n",
        "        pos (int, int): Tupla de dois inteiros que indica a posição no\n",
        "        grid.\n",
        "    \n",
        "    Returns:\n",
        "      (int, int): nova posição\n",
        "  '''\n",
        "  global rewards\n",
        "  if isinstance(dir, str):\n",
        "    dir = 'nslo'.index(dir.lower())\n",
        "  r = rewards[pos][dir]\n",
        "  if r == 10: # Isso significa que estávamos em A\n",
        "    nova_posicao = (4, 1)\n",
        "  elif r == 5: # Isso significa que estávamos em B\n",
        "    nova_posicao = (2, 3)\n",
        "  elif r == -1:\n",
        "    nova_posicao = pos\n",
        "  else:\n",
        "    funcao_movimento = (\n",
        "        lambda row, column: (row-1, column), # Norte\n",
        "        lambda row, column: (row+1, column), # Sul\n",
        "        lambda row, column: (row, column+1), # Leste\n",
        "        lambda row, column: (row, column-1) # Oeste\n",
        "    )[dir]\n",
        "    nova_posicao = funcao_movimento(*pos)\n",
        "  return nova_posicao"
      ],
      "metadata": {
        "id": "0fCb-aqNSnXY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Lembrando que:\n",
        "[$\\mathbb{E}[X]=\\sum^{\\infty}_{i=1}x_ip(x_i)$](https://pt.wikipedia.org/wiki/Valor_esperado) "
      ],
      "metadata": {
        "id": "YSDnvs4n4KfA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gamma = 0.9\n",
        "\n",
        "pi = numpy.asarray([0.25] * 4) # Política aleatória\n",
        "\n",
        "v = numpy.zeros((5, 5)) # Valor da política aleatória\n",
        "vo = numpy.zeros((5, 5)) # Valor da política ótima (Equação de Bellman)\n",
        "po = numpy.zeros((5, 5)) # Política ótima\n",
        "\n",
        "for t in range(20):\n",
        "  for row in range(5):\n",
        "    for column in range(5):\n",
        "      # Estados imediatamente próximos\n",
        "      directions = [mover(d, (row, column)) for d in 'nslo']\n",
        "      # Valores atuais dos estados imediatamente próximos\n",
        "      values = v[tuple(zip(*directions))]\n",
        "      optimal_values = vo[tuple(zip(*directions))]\n",
        "      # Valor da política aleatória\n",
        "      v[row][column] = numpy.sum(pi * (rewards[row][column] + (gamma * values)))\n",
        "      # Valor da política ótima\n",
        "      vo[row][column] = numpy.max(\n",
        "          (1 * (rewards[row][column] + (gamma * optimal_values)))\n",
        "      )\n",
        "      po[row][column] = numpy.argmax(\n",
        "          (1 * (rewards[row][column] + (gamma * optimal_values)))\n",
        "      )\n",
        "print(\"Valor dos estados na política aleatória\")\n",
        "print(numpy.round(v, 1))\n",
        "print(\"Valor dos estados na política ótima\")\n",
        "print(numpy.round(vo, 1))\n",
        "print(\"Política ótima\")\n",
        "print(numpy.vectorize('\\u2191\\u2193\\u2192\\u2190'.__getitem__)(po.astype(int)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OhQjez3Qe8h-",
        "outputId": "aca1d2e7-4615-467c-c659-4bc81539e037"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valor dos estados na política aleatória\n",
            "[[ 3.3  8.8  4.4  5.3  1.5]\n",
            " [ 1.5  3.   2.3  1.9  0.6]\n",
            " [ 0.1  0.8  0.7  0.4 -0.4]\n",
            " [-0.9 -0.4 -0.3 -0.6 -1.2]\n",
            " [-1.8 -1.3 -1.2 -1.4 -2. ]]\n",
            "Valor dos estados na política ótima\n",
            "[[22.  24.4 22.  19.4 17.5]\n",
            " [19.8 22.  19.8 17.8 16. ]\n",
            " [17.8 19.8 17.8 16.  14.4]\n",
            " [16.  17.8 16.  14.4 13. ]\n",
            " [14.4 16.  14.4 13.  11.7]]\n",
            "Política ótima\n",
            "[['→' '↑' '←' '↑' '←']\n",
            " ['↑' '↑' '↑' '←' '←']\n",
            " ['↑' '↑' '↑' '↑' '↑']\n",
            " ['↑' '↑' '↑' '↑' '↑']\n",
            " ['↑' '↑' '↑' '↑' '↑']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Políticas e valores\n",
        "\n",
        "* Comparando políticas:<br>\n",
        "$\n",
        "v_\\pi(s)\\ge v_{\\pi\\prime}(s)\\to\\pi\\ge\\pi\\prime\n",
        "$\n",
        "* Função estado-valor ótima:<br>\n",
        "$\n",
        "v_*(s)\\doteq\\max_\\pi v_\\pi(s)\\space s\\in S\n",
        "$\n",
        "* Função estado-ação-valor ótima:<br>\n",
        "$\n",
        "q_*(s,a)\\doteq\\max_\\pi q_\\pi(s,a)\\space s\\in S\\space e\\space a \\in A(s)\n",
        "$\n",
        "* Reescrevendo em função das equações acima:<br>\n",
        "$\n",
        "q_*(s,a)=\\mathbb{E}[R_{t+1}+\\gamma v_*(S_{t+1})|S_t=s, A_t=a]\n",
        "$\n",
        "* Equação de Bellman otimizada:<br>\n",
        "$\n",
        "v_*(s) = \\max_aq_*(s,a)\\\\\n",
        "= \\max_a\\mathbb{E}[R_{t+1}+\\gamma v_*(S_{t+1})|S_t=s,A_t=a]\\\\\n",
        "= \\max_a\\sum_{s\\prime,r}p(s\\prime,r|s,a)(r+\\gamma v_*(s\\prime))\n",
        "$\n",
        "* Equação de Bellman otimizada para $q$:<br>\n",
        "$\n",
        "q_*(s,a)=\\mathbb{E}\\left[R_{t+1}+\\gamma\\max_{a\\prime}q_*(S_{t+1},a\\prime)\\middle|S_t=s,A_t=a\\right]\\\\\n",
        "= \\sum_{s\\prime,r}p(s\\prime,r|s,a)\\left(r+\\max_{a\\prime}\\gamma q_*(s\\prime,a\\prime)\\right)\n",
        "$"
      ],
      "metadata": {
        "id": "i0haQGRpHIaT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Otimização e Aproximação\n",
        "\n",
        "* Política ótima muito difícil de se aprender em ambientes mais complexos\n",
        "* Entender o ambiente é importante e ajuda bastante, porém não é suficiente\n",
        "* Computacionalmente custoso mesmo em casos finitos\n",
        "* Precisa-se recorrer à aproximações para convergir modelos"
      ],
      "metadata": {
        "id": "9dJksfQMLj9B"
      }
    }
  ]
}